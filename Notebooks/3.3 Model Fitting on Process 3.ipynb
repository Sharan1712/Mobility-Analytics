{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHX8PDe_foYB"
      },
      "source": [
        "**Loaded packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwsjnOEYYaH9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest, chi2  \n",
        "from sklearn.pipeline import Pipeline\n",
        "import sklearn.metrics as metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE_vNEg9aLsW"
      },
      "source": [
        "**Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l82C1fgK07Jb"
      },
      "outputs": [],
      "source": [
        "train_process3 = pd.read_csv(\"../data/preprocessed/train_process3.csv\")\n",
        "test_process3 = pd.read_csv(\"../data/preprocessed/test_process3.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_process3.head()"
      ],
      "metadata": {
        "id": "J6wR2edzRFon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfuApUEqP9qw"
      },
      "outputs": [],
      "source": [
        "test_process3.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train-Validation Split**"
      ],
      "metadata": {
        "id": "OaY3bjn4b3DI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_process3.drop([\"Surge_Pricing_Type\",\"Trip_ID\"], axis=1)\n",
        "y = train_process3.Surge_Pricing_Type\n",
        "X_test = train_process3.drop([\"Trip_ID\"], axis=1)\n",
        "Trip_ID = train_process3.Trip_ID"
      ],
      "metadata": {
        "id": "UzftgWzGb3DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify = y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "iB7f2vfpb3DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the scores of the features using SelectKBest"
      ],
      "metadata": {
        "id": "Tfhs-s4xpRek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bestfeatures = SelectKBest(score_func = chi2, k='all')\n",
        "fit = bestfeatures.fit(X_train, y_train)\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(X.columns)\n",
        "featureScores = pd.concat([dfcolumns, dfscores], axis = 1)\n",
        "featureScores.columns = ['feature','Score']\n",
        "print(featureScores.sort_values('Score', ascending = False)) "
      ],
      "metadata": {
        "id": "EPsUceK3pRek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93hgKoBfMhkU"
      },
      "source": [
        "###Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtyA2N3-MhkU"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "pipe_rf  = Pipeline([('scaler', StandardScaler()), ('clf', RandomForestClassifier(random_state = 0))])\n",
        "\n",
        "# Decision Tree\n",
        "pipe_dt  = Pipeline([('scaler', StandardScaler()), ('clf', DecisionTreeClassifier(random_state = 0))])\n",
        "\n",
        "# Dummy (Baseline)\n",
        "pipe_dum = Pipeline([('scaler', StandardScaler()), ('clf', DummyClassifier(random_state = 0))])\n",
        "\n",
        "# K Nearest Neighbors\n",
        "pipe_knn = Pipeline([('scaler', StandardScaler()), ('clf', KNeighborsClassifier())])\n",
        "\n",
        "# Naive Bayes\n",
        "pipe_nb  = Pipeline([('scaler', StandardScaler()), ('clf', GaussianNB())])\n",
        "\n",
        "# Support Vector Machine\n",
        "pipe_svm = Pipeline([('scaler', StandardScaler()), ('clf', SVC(random_state = 0))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGjqQV9NMhkU"
      },
      "outputs": [],
      "source": [
        "pipelines = [pipe_rf, pipe_dt, pipe_dum, \n",
        "             pipe_knn, pipe_nb, pipe_svm]\n",
        "\n",
        "models = ['RandomForest', \n",
        "          'DecisionTree', \n",
        "          'Dummy(Baseline)', \n",
        "          'KNN', \n",
        "          'NaiveBayes',\n",
        "          'SupportVectorMachine']\n",
        "\n",
        "# Zipping the the strings and pipelines together and creating a dictionary\n",
        "model_pipelines = dict(zip(models, pipelines))\n",
        "model_pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-W4sQ6aMhkV"
      },
      "outputs": [],
      "source": [
        "# Dictionary containing the model names and their scores\n",
        "models_f1 = {}\n",
        "classification_report = {}\n",
        "test_preds = {}\n",
        "\n",
        "for name, pipe in model_pipelines.items():\n",
        "    print('\\n'+ name + ' Fitting')\n",
        "    pipe.fit(X_train, y_train)\n",
        "    print(name + ' (Macro Avg - F1 Score):')\n",
        "    \n",
        "    # Classification Report\n",
        "    report = metrics.classification_report(y_val, pipe.predict(X_val), output_dict=True)\n",
        "   \n",
        "    f1 = report['macro avg']['f1-score']\n",
        "    \n",
        "    #We predict on the test set given by the competition\n",
        "    test_pred = pipe.predict(X_test)\n",
        "    \n",
        "    # Assigning to the Dictionary\n",
        "    test_preds[name] = test_pred\n",
        "    classification_reports[name] = report\n",
        "    models_f1[name] = f1\n",
        "    \n",
        "    print(f1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the scores of each model"
      ],
      "metadata": {
        "id": "1l2QVtjzrlkI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3ppYDEdMhkV"
      },
      "outputs": [],
      "source": [
        "for i in sorted(models_f1, key=models_f1.get, reverse=True):\n",
        "    print(i, models_f1[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the test predictions to upload on the competition site"
      ],
      "metadata": {
        "id": "hPmeSiiirmjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in test_preds.items():\n",
        "  new_dict_data = dict(zip(Trip_ID.values,test_preds[k]))\n",
        "  df = pd.DataFrame(new_dict_data.items(), columns=['Trip_ID', 'Surge_Pricing_Type'])\n",
        "  df.to_csv('../submissions/Preprocess3/Preprocess3_{methodname}_test_prediction.csv'.format(methodname = k), index = False)"
      ],
      "metadata": {
        "id": "iKGu3cB8WzUy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "wEXJxbdhfTaU",
        "DHX8PDe_foYB",
        "sE_vNEg9aLsW",
        "FCGftUo5g_Ma",
        "gEnRUJ1AmBrR",
        "EZheiL2imWmK",
        "UUw3zno3m6vm",
        "D93XWr2_njVV"
      ],
      "name": "3.3 Model Fitting on Process 3.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}