{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHX8PDe_foYB"
      },
      "source": [
        "**Loaded packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwsjnOEYYaH9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest, chi2  \n",
        "from sklearn.pipeline import Pipeline\n",
        "import sklearn.metrics as metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE_vNEg9aLsW"
      },
      "source": [
        "**Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l82C1fgK07Jb"
      },
      "outputs": [],
      "source": [
        "train_process2 = pd.read_csv(\"../data/preprocessed/train_process2.csv\")\n",
        "test_process2 = pd.read_csv(\"../data/preprocessed/test_process2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_process2.head()"
      ],
      "metadata": {
        "id": "J6wR2edzRFon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfuApUEqP9qw"
      },
      "outputs": [],
      "source": [
        "test_process2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "API5yW291P7R"
      },
      "source": [
        "**Train-Validation Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z34rHn_t1P7S"
      },
      "outputs": [],
      "source": [
        "X = train_process2.drop([\"Surge_Pricing_Type\",\"Trip_ID\"], axis=1)\n",
        "y = train_process2.Surge_Pricing_Type\n",
        "X_test = test_process2.drop([\"Trip_ID\"], axis=1)\n",
        "Trip_ID = test_process2.Trip_ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JoN6nv81P7S"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify = y, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the scores of the features using SelectKBest"
      ],
      "metadata": {
        "id": "D93XWr2_njVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bestfeatures = SelectKBest(score_func = chi2, k='all')\n",
        "fit = bestfeatures.fit(X_train, y_train)\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(X.columns)\n",
        "featureScores = pd.concat([dfcolumns, dfscores], axis = 1)\n",
        "featureScores.columns = ['feature','Score']\n",
        "print(featureScores.sort_values('Score', ascending = False)) "
      ],
      "metadata": {
        "id": "aXxn1GwSnjVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waZsVJPH1P7T"
      },
      "source": [
        "###Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulbR1m3W1P7T"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "pipe_rf  = Pipeline([('scaler', StandardScaler()), ('clf', RandomForestClassifier(random_state = 0))])\n",
        "\n",
        "# Decision Tree\n",
        "pipe_dt  = Pipeline([('scaler', StandardScaler()), ('clf', DecisionTreeClassifier(random_state = 0))])\n",
        "\n",
        "# Dummy (Baseline)\n",
        "pipe_dum = Pipeline([('scaler', StandardScaler()), ('clf', DummyClassifier(random_state = 0))])\n",
        "\n",
        "# K Nearest Neighbors\n",
        "pipe_knn = Pipeline([('scaler', StandardScaler()), ('clf', KNeighborsClassifier())])\n",
        "\n",
        "# Naive Bayes\n",
        "pipe_nb  = Pipeline([('scaler', StandardScaler()), ('clf', GaussianNB())])\n",
        "\n",
        "# Support Vector Machine\n",
        "pipe_svm = Pipeline([('scaler', StandardScaler()), ('clf', SVC(random_state = 0))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZ7tMsGm1P7T"
      },
      "outputs": [],
      "source": [
        "pipelines = [pipe_rf, pipe_dt, pipe_dum, \n",
        "             pipe_knn, pipe_nb, pipe_svm]\n",
        "\n",
        "models = ['RandomForest', \n",
        "          'DecisionTree', \n",
        "          'Dummy(Baseline)', \n",
        "          'KNN', \n",
        "          'NaiveBayes',\n",
        "          'SupportVectorMachine']\n",
        "\n",
        "# Zipping the the strings and pipelines together and creating a dictionary\n",
        "model_pipelines = dict(zip(models, pipelines))\n",
        "model_pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxcajKBg1P7T"
      },
      "outputs": [],
      "source": [
        "# Dictionary containing the model names and their scores\n",
        "models_f1 = {}\n",
        "classification_report = {}\n",
        "test_preds = {}\n",
        "\n",
        "for name, pipe in model_pipelines.items():\n",
        "    print('\\n'+ name + ' Fitting')\n",
        "    pipe.fit(X_train, y_train)\n",
        "    print(name + ' (Macro Avg - F1 Score):')\n",
        "    \n",
        "    # Classification Report\n",
        "    report = metrics.classification_report(y_val, pipe.predict(X_val), output_dict=True)\n",
        "   \n",
        "    f1 = report['macro avg']['f1-score']\n",
        "    \n",
        "    #We predict on the test set given by the competition\n",
        "    test_pred = pipe.predict(X_test)\n",
        "    \n",
        "    # Assigning to the Dictionary\n",
        "    test_preds[name] = test_pred\n",
        "    classification_reports[name] = report\n",
        "    models_f1[name] = f1\n",
        "    \n",
        "    print(f1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the scores of each model"
      ],
      "metadata": {
        "id": "frvdm_uKrjHX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJy5r6CW1P7T"
      },
      "outputs": [],
      "source": [
        "for i in sorted(models_f1, key=models_f1.get, reverse=True):\n",
        "    print(i, models_f1[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the test predictions to upload on the competition site"
      ],
      "metadata": {
        "id": "WRP00FXCro12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in test_preds.items():\n",
        "  new_dict_data = dict(zip(Trip_ID.values,test_preds[k]))\n",
        "  df = pd.DataFrame(new_dict_data.items(), columns=['Trip_ID', 'Surge_Pricing_Type'])\n",
        "  df.to_csv('../submissions/Preprocess2/Preprocess2_{methodname}_test_prediction.csv'.format(methodname = k), index = False)"
      ],
      "metadata": {
        "id": "MKtM1fuRORuc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "wEXJxbdhfTaU",
        "DHX8PDe_foYB",
        "sE_vNEg9aLsW",
        "FCGftUo5g_Ma",
        "gEnRUJ1AmBrR",
        "EZheiL2imWmK",
        "UUw3zno3m6vm",
        "D93XWr2_njVV"
      ],
      "name": "3.2 Model Fitting on Process 2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}